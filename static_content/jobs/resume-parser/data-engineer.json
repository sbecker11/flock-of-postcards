{
  "contactInformation": "SHAWN BECKER\nLehi, UT \u2022 (857) 891-0896 \u2022 sbecker@alum.mit.edu",
  "position": "DATA ENGINEER / DATA ARCHITECT / MACHINE LEARNING",
  "professionalSummary": "As an experienced data engineering professional with expertise in Data Architecture and Technical Project Management, I excel in problem-solving and leading teams to deliver innovative solutions to complex challenges across diverse industries, including entertainment, healthcare, finance, and manufacturing. My expertise includes creating scalable, secure, high-volume data pipelines leveraging cloud infrastructure and domain-specific data architecture while employing machine learning models to optimize data-driven decision-making processes. I thrive in dynamic environments, applying Agile methodologies to facilitate my team's focus on building working increments of well-architecture solutions that meet product owners' expectations. Driven by a passion for continuous learning, I relish tackling new challenges and achieving excellence in every project.",
  "workExperience": [
    {
      "company": "Fannie Mae / Risk Works Analysis Data Lake",
      "location": "Washington, DC",
      "dateRange": "Feb 2024 \u2013 Jul 2024",
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Documented processes to build, test, and deploy data pipeline components for in-house ETL framework.",
        "Extensive work with SQL, AWS Redshift, Glue, S3, IAM, Lambda, REST, Postman, SNS, and dbt.",
        "Utilized Agile practices with Jira, including backlog refinements, sprint planning, daily scrums, bi-weekly sprint reviews, and end-of-sprint retrospectives. Enabled the product owner to review each shipped product increment, allowing for potential revision or re-prioritization of backlog items."
      ]
    },
    {
      "company": "The Cigna Group / Data Cybersecurity",
      "location": "Bloomfield, CT",
      "dateRange": "May 2023 - Dec 2023",
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Modernized apps via Jenkins CI/CD pipeline upgrade, integrating SetupTools, Artifactory/PyPI, SonarQube, and Xray.",
        "Investigated and implemented preparation of legacy ETL data pipeline components. Migration from on-prem Unity IoC apps to the AWS cloud using CDC.",
        "Engineered Python REST API enabling credential retrieval from CyberArk's identity management platform using mutual TLS/SSL authentication via AWS API Gateway",
        "Initiated CyberArk service updates to extract credentials at runtime, avoiding the need to access locally encrypted files and eliminating engineering efforts to satisfy cybersecurity requirements. The cost was reduced by 95% of the original for each password rollover event."
      ]
    },
    {
      "company": "Warner Brothers Interactive Entertainment",
      "location": "Waltham, MA",
      "dateRange": "Oct 2022 \u2013 Apr 2023",
      "position": "Senior Data Engineer / Data Scientist",
      "responsibilities": [
        "Utilized PySpark for ETL processes and Python for third-party integrations and dev-ops collaborations with Jenkins, DataDog, and ZenDesk. I leveraged Google BigQuery and AWS services, including Lambda, Aurora PostgreSQL, SalesForce, Snowflake, and AWS Glue.",
        "Developed high-volume pipeline ingress and integrations, enabling efficient game telemetry and user PII data transfer between WB-distributed games and leading marketing platforms using Segment CDP, Kafka, Redshift, Glue, and Airflow for orchestration.",
        "Conducted exploration and statistical analysis of marketing data, including principal component analysis, eigenvector decomposition, dimensionality reduction, vectorization, Bayesian clustering, and collaborative filtering. I used Jupyter, Python, Pandas, NumPy, Sci-kit Learn, and Keras for analytical processing and Seaborn, Plotly, and Matplotlib for data visualization.",
        "Practiced Agile SDLC in Jira with spring planning, daily scrums, and bi-weekly sprint reviews."
      ]
    },
    {
      "company": "Angel Studios",
      "location": "Provo, Utah",
      "dateRange": "Dec 2021 - Sep 2022",
      "position": "Data Scientist",
      "responsibilities": [
        "Used AWS SageMaker, Python, and Machine Learning packages, Pytorch and Keras, to build and optimize a supervised CNN for classifying movie frames from episodes stored in S3.",
        "Earned certifications in Advanced Learning Algorithms, Advanced SQL for Data Scientists, and Supervised Machine Learning: Regression & Classification, boosting professional skills.",
        "Conducted data exploration with machine learning algorithms using Jupyter, Python, Pandas, NumPy, Sci-kit Learn, and Keras for processing, and Seaborn, Plotly, and Matplotlib for data visualization to enhance analytical capabilities significantly.",
        "Developed effective Business Intelligence strategies using Looker and Tableau with Snowflake and Redshift for comprehensive sales and finance reporting."
      ]
    },
    {
      "company": "Greenseed Data Laboratory",
      "location": "Orem, Utah",
      "dateRange": "Nov 2020 - Nov 2021",
      "position": "Senior Data Engineer Data Scientist",
      "responsibilities": [
        "Conducted advanced statistical exploration of real-estate sales data using Python, Pandas, NumPy, SciPy, and Scikit-learn.",
        "Implemented a CI/CD pipeline using GitHub Actions with Coverage, SonarQube, and Xray",
        "Designed and built a custom star-schema data warehouse on PostgreSQL, using dimensional modeling, featuring SCD type-2 tables sharing a common streaming facts table.",
        "Enhanced machine learning skills with tutorials for TensorFlow, PyTorch, and Keras using Kaggle datasets."
      ]
    },
    {
      "company": "NuSkin",
      "location": "Provo, Utah",
      "dateRange": "Nov 2019 - Nov 2020",
      "position": "Senior Full Stack Developer",
      "responsibilities": [
        "Enhanced site registration and login pages by designing workflow and wireframes.",
        "Innovated Vue Vuetify components with NodeJS SCSS for improved functionality.",
        "Documented and launched new packages for company-wide use, enhancing efficiency.",
        "Internationalized content using Adobe Experience Cloud."
      ]
    },
    {
      "company": "SeniorLink / Vela",
      "location": "Boston, MA",
      "dateRange": "Mar 2017 - Nov 2019",
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Designed and deployed an AWS data pipeline for the Vela platform, which provided messaging, communication, and collaboration tools for the healthcare industry.",
        "Managed data ingress by queueing API Gateway-delivered message payloads into Amazon Kinesis Data Stream shards. Utilized SNS-triggered Python jobs running on serverless Lambdas to aggregate shard data into date-partitioned Parquet files in an S3 data lake.",
        "Performed ETL processes, extracting, transforming, and loading Parquet data from the data lake to Redshift via scheduled PySpark batch jobs on an EMR cluster orchestrated by Data Pipeline.",
        "Generated daily business intelligence reports using Tableau with Redshift OLAP.",
        "Coordinated with domestic and offshore development and quality assurance teams."
      ]
    },
    {
      "company": "ClipFile",
      "location": "Newton Center, MA",
      "dateRange": "Feb 2011 \u2013 Mar 2017",
      "position": "Technical Project Manager, Solutions Architect, Co-Founder",
      "responsibilities": [
        "Led a team to develop and launch a pioneering SaaS on the AWS platform, empowering individuals and content creators to search and share curated mindsets.",
        "Designed and implemented patented technology, creating a consumer-facing CMS that facilitated fuzzy matching among user-curated quotes and text fragments.",
        "Applied machine learning algorithms including principal component analysis, eigenvector decomposition, dimensionality reduction, vectorization, cosine similarities, K-means, Bayesian clustering, and collaborative filtering to implement fuzzy word matching and word clustering.",
        "Utilized a RESTful API interface for the in-app presentation layer and as a service interface for external client apps."
      ]
    },
    {
      "company": "Sierra Vista Group",
      "location": "Boston, MA",
      "dateRange": "Nov 2002 - Feb 2011",
      "position": "Technical Program Manager, Solutions Architect / Co-Founder",
      "responsibilities": [
        "Identified profitable opportunities in product development, software engineering, and data modeling and successfully negotiated budgets and project milestones with C-level management.",
        "Recruited high-value independent consultants specializing in DevOps, full-stack development, database administration, graphic design, user experience, and quality assurance.",
        "Developed and aligned comprehensive project schedules and detailed technical specifications with specific business requirements within strict budgets using the Waterfall SDLC process.",
        "Mitigated schedule and budget issues with client-management when required.",
        "Managed IT strategies customized for clients in the entertainment, medical services, manufacturing, insurance, and cyber security industries, including AMI, Rowe Jukeboxes, Eleven Systems, Coca-Cola Corp. Europe, Medical Services Corp., and Intrusic Cyber Security."
      ]
    }
  ],
  "education": [
    {
      "institution": "Massachusetts Institute of Technology, Cambridge, Massachusetts",
      "degree": "PhD, Media Arts & Sciences, Machine Vision/Video Coding"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "MS, Computer Science, Medical Imaging/Computer Graphics"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "BS, Design Engineering Technology, CAD/CAE/CAM"
    }
  ],
  "skills": "AWS Architecture \u2022 Amazon S3 \u2022 DBT \u2022 Glue \u2022 Glue Catalog \u2022 Lambdas \u2022 Step Functions \u2022 Kinesis Data Streams \u2022 Kafka \u2022 SQS \u2022 SNS \u2022 SMS \u2022 EC2 \u2022 Redshift \u2022 DynamoDB \u2022 SimpleDB \u2022 ElastiCache \u2022 Aurora \u2022 Snowflake \u2022 Looker \u2022 Tableau \u2022 Databricks Medallion Architecture \u2022 Delta Lake \u2022 Databricks Lakehouse \u2022 CloudFormation \u2022 Docker \u2022 Kubernetes \u2022 ECR \u2022 ECS \u2022 EKS \u2022 Fargate \u2022 Data Pipeline \u2022 PySpark \u2022 EMR \u2022 AWS Migration Service \u2022 SQL \u2022 Python \u2022 Java \u2022 Airflow \u2022 Amazon QuickSight \u2022 Git \u2022 REST API \u2022 CI/CD \u2022 Jenkins \u2022 GitHub Actions \u2022 Unit Testing \u2022 Integration Testing \u2022 SageMaker \u2022 GitHub \u2022 Bitbucket \u2022 PostgreSQL \u2022 Oracle \u2022 MS SQL Server \u2022 Machine Learning \u2022 Regression \u2022 Classification \u2022 CNN \u2022 Clustering \u2022 Dimensionality Reduction \u2022 PCA \u2022 RAG \u2022 Encoding \u2022 MSProject \u2022 Visio \u2022 Office 365 \u2022 Agile Scrum SDLC \u2022 Scheduling \u2022 Budgets \u2022 Milestones \u2022 Risk Mitigation \u2022 Stakeholder Management \u2022 Resource Allocation \u2022 Leadership \u2022 Tutoring \u2022 Team Building \u2022 Offshore Management \u2022 Cybersecurity \u2022 DataDog \u2022 CloudWatch \u2022 Confluence \u2022 Jira \u2022 Certified Scrum Master\u00a9",
  "certifications": "https://www.linkedin.com/in/shawnbecker/details/certifications/",
  "publications": "https://independent.academia.edu/shawnbecker",
  "patents": "https://patents.justia.com/inventor/shawn-c-becker",
  "websites": [
    "https://www.linkedin.com/in/shawnbecker",
    "http://spexture.com"
  ]
}